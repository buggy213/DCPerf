[uwsgi]
# uWSGI + HAProxy Load Balanced Configuration
# This config starts N uWSGI workers, each running a Proxygen server on a unique port
# HAProxy load balances requests across all workers

# =============================================================================
# Core Settings
# =============================================================================

# Load proxygen_wsgi to register postfork hooks
# Use wsgi-file to directly load the Python file
wsgi-file = proxygen_wsgi.py

# Master process (manages workers)
master = true

# Number of worker processes
# Override with --set workers=N or environment variable UWSGI_WORKERS
# Default to 8 if not specified
processes = %(workers)
workers = 8

# Enable lazy-apps mode (load application after worker fork)
# This is CRITICAL for Proxygen to work correctly
# Without this, Proxygen server would start in master process before fork
lazy-apps = true

# Enable threads for Python (needed for Proxygen's threading)
enable-threads = true

# =============================================================================
# Socket Configuration
# =============================================================================

# uWSGI requires a socket to start, even if not actively used
# We use a Unix socket for uWSGI master communication
# Proxygen handles all actual HTTP traffic on its own port
socket = /tmp/uwsgi-loadbalanced.sock
chmod-socket = 666

# Keep socket for graceful reloads
vacuum = true

# =============================================================================
# Port Configuration
# =============================================================================

# Environment variables are set by start_loadbalanced_server.py:
#   PROXYGEN_BASE_PORT - Starting port for workers (default: 8001)
#   PROXYGEN_THREADS - Number of threads per worker (default: 14)
#
# These are passed via the Python subprocess environment and should NOT be
# redefined here using "env =" directives, as that would override the values.
#
# Port calculation in proxygen_wsgi.py:
#   Worker 1 port = PROXYGEN_BASE_PORT + 1 - 1 = base_port
#   Worker 2 port = PROXYGEN_BASE_PORT + 2 - 1 = base_port + 1
#   Worker N port = PROXYGEN_BASE_PORT + N - 1

# =============================================================================
# Process Management
# =============================================================================

# Reload workers after serving N requests (detect memory leaks)
max-requests = 10000

# Add jitter to max-requests to avoid thundering herd
max-requests-delta = 1000

# Reload worker if memory exceeds 2GB
reload-on-rss = 2048

# Kill worker if request takes longer than 60 seconds (harakiri)
harakiri = 60

# Reload workers gracefully on SIGHUP
die-on-term = true

# Graceful reload timeout
worker-reload-mercy = 30

# =============================================================================
# Logging
# =============================================================================

# Don't specify logto - let uWSGI log naturally to stdout
# (Python orchestration script captures stdout via subprocess.PIPE)

# Log format with timestamps
log-date = true

# Disable request logging (Proxygen handles this)
disable-logging = true

# But log important events (worker spawn, reload, etc.)
log-master = true

# =============================================================================
# Performance Tuning
# =============================================================================

# Listen queue size
listen = 1024

# Enable thunder lock (prevent thundering herd)
thunder-lock = true

# Cheaper subsystem (dynamic worker scaling)
# Disabled for load balanced setup (we want all workers running)
# cheaper-algo = spare
# cheaper = 2
# cheaper-initial = 4
# cheaper-step = 1

# =============================================================================
# Health & Monitoring
# =============================================================================

# Stats server (optional - for monitoring)
# Uncomment to enable:
# stats = 127.0.0.1:9191
# stats-http = true

# Memory report (log memory usage)
memory-report = true

# =============================================================================
# Vacuum & Cleanup
# =============================================================================

# Clean up on exit
vacuum = true

# =============================================================================
# Python Environment
# =============================================================================

# Disable buffering for real-time logs
env = PYTHONUNBUFFERED=1

# Django settings module
# Set via environment variable: DJANGO_SETTINGS_MODULE
# env = DJANGO_SETTINGS_MODULE=django_workload.settings

# =============================================================================
# Notes
# =============================================================================
#
# Usage:
#   1. Start uWSGI with this config:
#      UWSGI_WORKERS=8 PROXYGEN_BASE_PORT=8001 uwsgi --ini uwsgi_loadbalanced.ini
#
#   2. Each worker will automatically:
#      - Calculate its port: PROXYGEN_BASE_PORT + worker_id - 1
#      - Start Proxygen server on that port
#      - Handle requests asynchronously via Proxygen
#
#   3. HAProxy load balances across all worker ports (8001-8008)
#
# Architecture:
#   Client → HAProxy:8000
#              ↓
#       [Load Balancer]
#              ↓
#   ┌──────┬──────┬──────┐
#   ↓      ↓      ↓      ↓
#  uWSGI  uWSGI  uWSGI  uWSGI
#  Worker Worker Worker Worker
#    1      2      3      4
#    ↓      ↓      ↓      ↓
# Proxygen Proxygen Proxygen Proxygen
#  :8001   :8002   :8003   :8004
#
# Benefits:
#   - uWSGI process management (harakiri, memory limits, graceful reload)
#   - Proxygen async HTTP (high performance, concurrent requests)
#   - HAProxy load balancing (even distribution, health checks)
